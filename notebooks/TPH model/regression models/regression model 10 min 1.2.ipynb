{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model TPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import re\n",
    "from dateutil.parser import parse\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import missingno as msno\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy\n",
    "import researchpy as rp\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "#import pacmap\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Import Halving Grid Search\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "import xgboost as xgb\n",
    "from scipy.stats import kurtosis,skew\n",
    "from numpy import mean,sqrt,square\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "sns.set_style(\"darkgrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que filtra tags por alta correlación\n",
    "def corrkill(dataframe, features, corr_cut=0.8):\n",
    "\n",
    "    df = dataframe[features]\n",
    "    dfcorr = pd.DataFrame(np.triu(df.corr()), columns=df.columns, index=df.columns)\n",
    "    dfcorr = dfcorr.stack().reset_index()\n",
    "    dfcorr.columns = ['Feat1','Feat2','Val']\n",
    "    dfcorr = dfcorr[~dfcorr['Val'].isin([0,1])]\n",
    "    dfcorr = dfcorr[dfcorr['Val'].abs()>corr_cut]\n",
    "    dfcorr[\"Val\"]=dfcorr[\"Val\"].abs()\n",
    "    \n",
    "    return list(dfcorr['Feat2']), dfcorr.sort_values(by=\"Val\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_interes=['pyrite law', 'chalcopyrite law',\n",
    "       'chalcocite law', 'covelin law', 'crusher index', 'sag power index',\n",
    "       'ball work index', 'bornite law','charge cell', 'TPH','water', 'speed','HH TPH', 'granulometry', 'Edad','loss of TPH',\n",
    "       \"power\",\"solid percentage\",\"HH charge cell\",\"LL charge cell\",\"delta HH TPH\",\"delta HH charge cell\",\"delta LL charge cell\"]\n",
    "variables_interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read\n",
    "tags=pd.read_excel(\"../../../data/meta data/tags relevantes.xlsx\")\n",
    "tags_cc=tags.tag.to_list()\n",
    "dic={}\n",
    "for i,j in zip(tags.tag,tags.description):\n",
    "    dic[i]=j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se lee csv\n",
    "liners_age=pd.read_csv('../../../data/consolidated data/liners_age_03January2022.csv', parse_dates=['Timestamp'], index_col='Timestamp')\n",
    "# Se lee csv\n",
    "cleaned=pd.read_csv('../../../data/consolidated data/cleaned_15December2022.csv', parse_dates=['Timestamp'], index_col='Timestamp')\n",
    "cleaned.sort_index(inplace=True)\n",
    "cleaned.rename(columns=dic,inplace=True)\n",
    "df_cleaned_age=cleaned.join(liners_age).dropna()\n",
    "df_cleaned_age[\"delta HH TPH\"]=df_cleaned_age[\"HH TPH\"]-df_cleaned_age[\"TPH\"]\n",
    "df_cleaned_age[\"delta HH charge cell\"]=df_cleaned_age[\"HH charge cell\"]-df_cleaned_age[\"charge cell\"]\n",
    "df_cleaned_age[\"delta LL charge cell\"]=df_cleaned_age[\"charge cell\"]-df_cleaned_age[\"LL charge cell\"]\n",
    "df_cleaned_age[\"loss of TPH\"]=df_cleaned_age[\"delta HH TPH\"].apply(lambda x: 1 if x>100 else 0)\n",
    "df_cleaned_age=df_cleaned_age[variables_interes]\n",
    "df_cleaned_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_age[\"TPH\"].ewm(span=5,min_periods=0,ignore_na=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_cleaned_age.dropna().corr()\n",
    "corr_tph=pd.DataFrame(df_corr.abs().TPH.sort_values(ascending=False))\n",
    "top_corr=corr_tph[corr_tph.TPH>=0]\n",
    "top_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "      \n",
    "    targets = [\"TPH\",\"Edad\",\"loss of TPH\",\"HH TPH\"]\n",
    "    df_vars = df.copy()\n",
    "    column_inicial=df_vars.columns\n",
    "\n",
    "    for column in df_vars:\n",
    "    \n",
    "        if (column not in targets):\n",
    "\n",
    "            ## 10 min\n",
    "            #df_vars[f\"skew_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x:skew(x))\n",
    "            #df_vars[f\"kurt_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x:kurtosis(x))\n",
    "            df_vars[f\"mean_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x:np.nanmean(list(x)))\n",
    "            df_vars[f\"max_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x:np.nanmax(list(x)))\n",
    "            #df_vars[f\"sum_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x:np.nansum(list(x)))\n",
    "            df_vars[f\"min_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x:np.nanmin(list(x)))\n",
    "            df_vars[f\"rms_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x: sqrt(mean(square(list(x)))))\n",
    "            df_vars[f\"var_{column}_10\"]=df_vars[column].rolling(window=10).apply(lambda x: np.nanvar(x))\n",
    "\n",
    "            # 5 min\n",
    "            df_vars[f\"mean_{column}_5\"]=df_vars[column].rolling(window=5).apply(lambda x:np.nanmean(list(x)))\n",
    "            df_vars[f\"max_{column}_5\"]=df_vars[column].rolling(window=5).apply(lambda x:np.nanmax(list(x)))\n",
    "            #df_vars[f\"sum_{column}_5\"]=df_vars[column].rolling(window=5).apply(lambda x:np.nansum(list(x)))\n",
    "            df_vars[f\"min_{column}_5\"]=df_vars[column].rolling(window=5).apply(lambda x:np.nanmin(list(x)))\n",
    "            df_vars[f\"rms_{column}_5\"]=df_vars[column].rolling(window=5).apply(lambda x: sqrt(mean(square(list(x)))))\n",
    "            df_vars[f\"var_{column}_5\"]=df_vars[column].rolling(window=5).apply(lambda x: np.nanvar(x))\n",
    "\n",
    "            # 3 min\n",
    "            #df_vars[f\"skew_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x:skew(x))\n",
    "            #df_vars[f\"kurt_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x:kurtosis(x))\n",
    "            df_vars[f\"mean_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x:np.nanmean(list(x)))\n",
    "            df_vars[f\"max_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x:np.nanmax(list(x)))\n",
    "            #df_vars[f\"sum_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x:np.nansum(list(x)))\n",
    "            df_vars[f\"min_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x:np.nanmin(list(x)))\n",
    "            df_vars[f\"rms_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x: sqrt(mean(square(list(x)))))\n",
    "            df_vars[f\"var_{column}_3\"]=df_vars[column].rolling(window=3).apply(lambda x: np.nanvar(x))\n",
    "          \n",
    "\n",
    "    for column in column_inicial:\n",
    "\n",
    "        if (column not in targets):\n",
    "            \n",
    "            # lags  \n",
    "            df_vars[f\"{column}_(t-1)\"] = df_vars[column].shift(1)\n",
    "            df_vars[f'{column}_(t-2)'] = df_vars[column].shift(2)\n",
    "            df_vars[f'{column}_(t-3)'] = df_vars[column].shift(3)\n",
    "            df_vars[f'{column}_(t-4)'] = df_vars[column].shift(4)\n",
    "            df_vars[f'{column}_(t-5)'] = df_vars[column].shift(5)\n",
    "           \n",
    "    \n",
    "    return df_vars\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features=feature_engineering(df_cleaned_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda en csv\n",
    "df_features.to_csv('../../../data/processed data/df_feature_engineering_'+pd.to_datetime('today').strftime('%d%B%Y')+'.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read df full csv\n",
    "df_features0=pd.read_csv('../../../data/processed data/df_feature_engineering_18December2022.csv', parse_dates=['Timestamp'], index_col='Timestamp')#[\"2020\":\"2021\"]\n",
    "df_features0[\"TPH\"]=df_features0[\"TPH\"].shift(-10)\n",
    "df_features0[\"loss of TPH\"]=df_features0[\"loss of TPH\"].shift(-10)\n",
    "df_features0.dropna(inplace=True)\n",
    "df_features0.sort_index(inplace=True)\n",
    "df_features0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando si hay duplicados\n",
    "u=[i for i in df_features0.columns if not re.match(\".*delta HH TPH\",i) ]\n",
    "df_features=df_features0[u].copy()\n",
    "df_features.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlación entre variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen tags altamente correlacionados y matriz que permite visualizar cuales son los par de tags altamente correlacionados\n",
    "collinearity, table_cor=corrkill(df_features,df_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags altamente correlacionados\n",
    "table_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df_features.dropna().corr()\n",
    "corr_tph=pd.DataFrame(df_corr.abs().TPH.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr=corr_tph[corr_tph.TPH>=0.25]\n",
    "top_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Equilibrio de eventos de perdidas de TPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "entrenamiento=pd.concat([df_features[\"2020-01\":\"2020-03\"],df_features[\"2020-05\"],df_features[\"2020-07\":\"2020-12\"],df_features[\"2021-01\":\"2021-08\"],df_features[\"2021-10\"],df_features[\"2021-12\"]])\n",
    "entrenamiento.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación\n",
    "validacion=pd.concat([df_features[\"2020-06\"],df_features[\"2021-11\"]])\n",
    "validacion.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test=pd.concat([df_features[\"2020-04\"],df_features[\"2021-09\"],df_features[\"2022\"]])\n",
    "test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=df_features.columns.to_list()\n",
    "tags.remove(\"loss of TPH\")\n",
    "#tags.remove(\"TPH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobremuestreo: Aumentar numero de datos de la clase minoritaria\n",
    "# ROS(Duplica clases):\n",
    "ros=RandomOverSampler(random_state=0) # Random_state=0\n",
    "\n",
    "# ROS:\n",
    "Xtrain, Ytrain=ros.fit_resample(entrenamiento[tags],entrenamiento[\"loss of TPH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ytrain reg\n",
    "Ytrain=Xtrain[\"TPH\"]\n",
    "Xtrain=Xtrain.drop(columns=[\"TPH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yval reg\n",
    "Yval=validacion[\"TPH\"]\n",
    "Xval=validacion.drop(columns=[\"TPH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest0=test[test[\"loss of TPH\"]==0][\"TPH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest1=test[test[\"loss of TPH\"]==1][\"TPH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest0=test[test[\"loss of TPH\"]==0].drop(columns=[\"TPH\",\"loss of TPH\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest1=test[test[\"loss of TPH\"]==1].drop(columns=[\"TPH\",\"loss of TPH\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ytest reg\n",
    "Ytest=test[\"TPH\"]\n",
    "Xtest=test.drop(columns=[\"TPH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unión del conjunto de Entrenamiento y Validación:\n",
    "Entre_Vali_features=pd.concat([Xval,Xtrain])\n",
    "Entre_Vali_target=pd.concat([Yval,Ytrain])\n",
    "\n",
    "#Indices para separar ambos conjuntos:\n",
    "Entre_indice=np.full(len(validacion),-1)\n",
    "Vali_indice=np.full(len(entrenamiento),0)\n",
    "Indices=np.append(Entre_indice,Vali_indice)\n",
    "x=PredefinedSplit(Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Color_loss=test[\"loss of TPH\"]\n",
    "Color_loss=Color_loss.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "\n",
    "preprocessing_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('MinMax', MinMaxScaler(),\n",
    "        Xtrain.columns.to_list()\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocesamiento\", preprocessing_transformer), \n",
    "     (\"clf\", xgb.XGBRegressor(seed=1,eval_metric='rmse'\n",
    "     ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest)\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest, Ypred),'\\n','RMSE: ',mean_squared_error(Ytest, Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance=pd.DataFrame({\"tag\":Xtrain.columns,\"importance\":pipe[\"clf\"].feature_importances_}).sort_values(by=\"importance\",ascending=False).reset_index(drop=True)\n",
    "df_importance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\"\n",
    "fig=df_importance[\"importance\"].plot(kind='hist')\n",
    "fig.update_layout(height=500, width=1200,title=\"Feature importance XGBoost (Gain)\",) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig = go.Figure([go.Bar(x=df_importance[\"tag\"], y=df_importance[\"importance\"])])\n",
    "fig.update_layout(height=500, width=1200,title=\"Feature importance XGBoost (Gain)\",) \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_fs=df_importance[:100].tag.to_list()\n",
    "xgboost_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se obtienen tags altamente correlacionados y matriz que permite visualizar cuales son los par de tags altamente correlacionados\n",
    "collinearity, table_cor=corrkill(Xtrain,xgboost_fs,corr_cut=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags altamente correlacionados\n",
    "table_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_select = [i for i in xgboost_fs if i not in collinearity]\n",
    "len(tag_select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "\n",
    "preprocessing_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('MinMax', MinMaxScaler(),\n",
    "        tag_select\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocesamiento\", preprocessing_transformer), \n",
    "     (\"clf\", xgb.XGBRegressor(seed=1,eval_metric='rmse'\n",
    "     ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest)\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest, Ypred),'\\n','RMSE: ',mean_squared_error(Ytest, Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "\n",
    "preprocessing_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('MinMax', MinMaxScaler(),\n",
    "        tag_select\n",
    "        #features.columns.to_list()\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocesamiento\", preprocessing_transformer), \n",
    "        #(\"Selection\", SelectPercentile(f_classif, percentile=10)),\n",
    "        #(\"PCA\",PCA(n_components=150 )), #0.08\n",
    "     (\"reg\", xgb.XGBRegressor(seed=1,eval_metric='rmse'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "param_grid_reg = {'reg__learning_rate': list(np.linspace(0.001,1,10)), # Boosting learning rate\n",
    "                  'reg__gamma':list(np.linspace(0.0001,50,5)), # Minimum loss reduction required to make a further partition on a leaf node of the tree.\n",
    "                  #'reg__max_depth':[5,10,12,15,20], # Maximum tree depth for base learners.\n",
    "                  #'reg__min_child_weight':[10,5,1,2,3], # Minimum sum of instance weight(hessian) needed in a child.\n",
    "                  #'reg__colsample_bytree':[0.5,0.8,1], # Subsample ratio of columns when constructing each tree.\n",
    "                  'reg__n_estimators': [100,200,300], # Number of gradient boosted trees.   \n",
    "                  #'reg__reg_alpha': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "              #'reg__reg_lambda': [0,0.1,0.2,0.4,0.8,1.6,3.2,6.4,12.8,25.6,51.2,102.4,200],\n",
    "               #'Selection__percentile': [10,20,30,50,70,80,100]              \n",
    "                 } \n",
    "\n",
    "# Clasificación\n",
    "gs_reg = HalvingGridSearchCV(pipe, param_grid_reg, scoring='neg_mean_absolute_error',cv=x,refit=True,\n",
    "                             verbose=10,\n",
    "                             aggressive_elimination=True\n",
    "                            )\n",
    "\n",
    "# Fit\n",
    "gs_reg.fit(Entre_Vali_features, Entre_Vali_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_reg.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "Ypred= gs_reg.predict(Xtest)\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest, Ypred),'\\n','RMSE: ',mean_squared_error(Ytest, Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_select=['min_water_3',\n",
    " 'min_solid percentage_10',\n",
    " 'HH TPH',\n",
    " 'max_delta LL charge cell_10',\n",
    " 'power',\n",
    " 'rms_delta LL charge cell_3',\n",
    " 'var_delta HH charge cell_10',\n",
    " 'max_covelin law_10',\n",
    " 'LL charge cell_(t-2)',\n",
    " 'min_granulometry_5',\n",
    " 'max_bornite law_10',\n",
    " 'min_charge cell_5',\n",
    " 'chalcocite law_(t-2)',\n",
    " 'max_sag power index_5',\n",
    " 'min_speed_3',\n",
    " 'var_bornite law_3',\n",
    " 'var_speed_3',\n",
    " 'min_pyrite law_10',\n",
    " 'crusher index_(t-5)',\n",
    " 'var_power_3',\n",
    " 'var_chalcocite law_3',\n",
    " 'var_bornite law_5',\n",
    " 'var_solid percentage_3',\n",
    " 'var_speed_10',\n",
    " 'ball work index_(t-1)',\n",
    " 'var_chalcocite law_5',\n",
    " 'var_water_3',\n",
    " 'chalcopyrite law_(t-5)',\n",
    " 'var_crusher index_10',\n",
    " 'var_chalcopyrite law_3',\n",
    " 'var_granulometry_3',\n",
    " 'var_delta HH charge cell_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamiento de datos\n",
    "\n",
    "preprocessing_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('MinMax', MinMaxScaler(),\n",
    "        tag_select\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"preprocesamiento\", preprocessing_transformer), \n",
    "     (\"clf\", xgb.XGBRegressor(seed=1,eval_metric='rmse',gamma= 12.500074999999999, learning_rate=0.112, n_estimators= 100\n",
    "     \n",
    "     ))\n",
    "    ]\n",
    ")\n",
    "pipe.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "Ypred= pipe.predict(Xtest0)\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest0, Ypred),'\\n','RMSE: ',mean_squared_error(Ytest0, Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "Ypred= pipe.predict(Xtest1)\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest1, Ypred),'\\n','RMSE: ',mean_squared_error(Ytest1, Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest)\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest, Ypred),'\\n','RMSE: ',mean_squared_error(Ytest, Ypred, squared=False),'\\n','MAPE :',mean_absolute_percentage_error(Ytest, Ypred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=Ypred[:10000], y=Ytest[:10000],\n",
    "                    mode='markers',\n",
    "                    name='(Pred,Test)'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=[i for i in range(2500,4700)], y=[i for i in range(2500,4700)],\n",
    "                    mode='markers', name='Identidad'))\n",
    "                    \n",
    "fig.update_layout(height=500, width=1200, title_text=\"Scatter predict/test\", xaxis_title=\"Predict\",\n",
    "    yaxis_title=\"Test\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=Ypred[:10000], \n",
    "                    mode='lines',name=\"predict\"\n",
    "                    ))\n",
    "\n",
    "fig.add_trace(go.Scatter(y=Ytest[:10000],\n",
    "                    mode='lines',name=\"Test\",#marker=dict(color=list(Color_loss[:1000]))\n",
    "                    ))\n",
    "\n",
    "fig.update_layout(height=500, width=1200, title_text=\"TPH vs TPH predict\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograma del error RMSE y desviación estandar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Ytest-Ypred).abs().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Ytest-Ypred).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.plotting.backend = \"plotly\"\n",
    "df_dist_error=pd.DataFrame()\n",
    "df_dist_error[\"Error\"]=(Ytest-Ypred)#.abs()\n",
    "fig=df_dist_error[\"Error\"].plot(kind='hist')\n",
    "fig.update_layout(height=500, width=1200,title=\"Distribución Error RMSE\") \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2020**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest[\"2020\"])\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest[\"2020\"], Ypred),'\\n','RMSE: ',mean_squared_error(Ytest[\"2020\"], Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2021**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest[\"2021\"])\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest[\"2021\"], Ypred),'\\n','RMSE: ',mean_squared_error(Ytest[\"2021\"], Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2022**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest[\"2022-01\"])\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest[\"2022-01\"], Ypred),'\\n','RMSE: ',mean_squared_error(Ytest[\"2022-01\"], Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred= pipe.predict(Xtest[\"2022-02\"])\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(Ytest[\"2022-02\"], Ypred),'\\n','RMSE: ',mean_squared_error(Ytest[\"2022-02\"], Ypred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation time series predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2021\n",
    "test_time_serie=Xtest[\"2020\"]\n",
    "test_time_serie[\"TPH\"]=Ytest[\"2020\"]\n",
    "test_time_serie[\"TPH predict\"]=pipe.predict(test_time_serie)\n",
    "\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"]),'\\n','RMSE: ',mean_squared_error(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"], squared=False))\n",
    "test_time_serie[\"TPH\"]=test_time_serie[\"TPH\"].shift(10)\n",
    "test_time_serie.dropna(inplace=True)\n",
    "data=test_time_serie\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos=tuple([\"TPH & HH TPH\", \"charge cell\",\"granulometry\",\"SPI\",\"speed\",\"solid percentage\"])\n",
    "fig = make_subplots(\n",
    "    rows=6, cols=1,\n",
    "    subplot_titles=titulos,\n",
    "    #subplot_titles=tuple(\"TPH y HH TPH,\"),\n",
    "     shared_xaxes=True\n",
    "    )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH predict'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH predict\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"HH TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "#fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"], ##FF6511\n",
    "#                    mode='lines',\n",
    "#                    name=\"regressor model TPH\",line=dict(width=1,color=\"black\" ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1) \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['LL charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)   \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['granulometry'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='granulometry',line=dict(width=3,),legendgroup = '1'),row=3, col=1)  \n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['sag power index'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"sag power index\",line=dict(width=3, ),legendgroup = '1'),row=4, col=1)  \n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['speed'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"speed\",line=dict(width=3, ),legendgroup = '1'),row=5, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['solid percentage'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='solid percentage',line=dict(width=3, ),legendgroup = '1'),row=6, col=1)  \n",
    "\n",
    "\n",
    "#for i in range(1,6):\n",
    "#   for j in range(1,4):\n",
    "#        fig.update_xaxes(tickformat=\"%H:%M\",row=i, col=j)\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=1500, title_text=\"Temporal signal analysis\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "#\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH'))\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH predict'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"HH TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='HH TPH'))\n",
    "\n",
    "fig.update_layout(height=500, width=1200, title_text=\"TPH vs TPH predict\"#,xaxis6_rangeslider_visible=True\n",
    ",#template=\"plotly_dark\"\n",
    ")                   \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"file.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2021\n",
    "test_time_serie=Xtest[\"2021\"]\n",
    "test_time_serie[\"TPH\"]=Ytest[\"2021\"]\n",
    "test_time_serie[\"TPH predict\"]=pipe.predict(test_time_serie)\n",
    "\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"]),'\\n','RMSE: ',mean_squared_error(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"], squared=False))\n",
    "test_time_serie[\"TPH\"]=test_time_serie[\"TPH\"].shift(10)\n",
    "test_time_serie.dropna(inplace=True)\n",
    "data=test_time_serie\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos=tuple([\"TPH & HH TPH\", \"charge cell\",\"granulometry\",\"SPI\",\"speed\",\"solid percentage\"])\n",
    "fig = make_subplots(\n",
    "    rows=6, cols=1,\n",
    "    subplot_titles=titulos,\n",
    "    #subplot_titles=tuple(\"TPH y HH TPH,\"),\n",
    "     shared_xaxes=True\n",
    "    )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH predict'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH predict\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"HH TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "#fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"], ##FF6511\n",
    "#                    mode='lines',\n",
    "#                    name=\"regressor model TPH\",line=dict(width=1,color=\"black\" ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1) \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['LL charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)   \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['granulometry'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='granulometry',line=dict(width=3,),legendgroup = '1'),row=3, col=1)  \n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['sag power index'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"sag power index\",line=dict(width=3, ),legendgroup = '1'),row=4, col=1)  \n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['speed'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"speed\",line=dict(width=3, ),legendgroup = '1'),row=5, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['solid percentage'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='solid percentage',line=dict(width=3, ),legendgroup = '1'),row=6, col=1)  \n",
    "\n",
    "\n",
    "#for i in range(1,6):\n",
    "#   for j in range(1,4):\n",
    "#        fig.update_xaxes(tickformat=\"%H:%M\",row=i, col=j)\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=1500, title_text=\"Temporal signal analysis\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "#\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH'))\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH predict'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"HH TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='HH TPH'))\n",
    "\n",
    "fig.update_layout(height=500, width=1200, title_text=\"TPH vs TPH predict\"#,xaxis6_rangeslider_visible=True\n",
    ",#template=\"plotly_dark\"\n",
    ")                   \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2022-01\n",
    "test_time_serie=Xtest[\"2022-01\"]\n",
    "test_time_serie[\"TPH\"]=Ytest[\"2022-01\"]\n",
    "test_time_serie[\"TPH predict\"]=pipe.predict(test_time_serie)\n",
    "\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"]),'\\n','RMSE: ',mean_squared_error(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"], squared=False))\n",
    "test_time_serie[\"TPH\"]=test_time_serie[\"TPH\"].shift(10)\n",
    "test_time_serie.dropna(inplace=True)\n",
    "data=test_time_serie\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos=tuple([\"TPH & HH TPH\", \"charge cell\",\"granulometry\",\"SPI\",\"speed\",\"solid percentage\"])\n",
    "fig = make_subplots(\n",
    "    rows=6, cols=1,\n",
    "    subplot_titles=titulos,\n",
    "    #subplot_titles=tuple(\"TPH y HH TPH,\"),\n",
    "     shared_xaxes=True\n",
    "    )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH predict'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH predict\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"HH TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "#fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"], ##FF6511\n",
    "#                    mode='lines',\n",
    "#                    name=\"regressor model TPH\",line=dict(width=1,color=\"black\" ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1) \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['LL charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)   \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['granulometry'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='granulometry',line=dict(width=3,),legendgroup = '1'),row=3, col=1)  \n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['sag power index'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"sag power index\",line=dict(width=3, ),legendgroup = '1'),row=4, col=1)  \n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['speed'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"speed\",line=dict(width=3, ),legendgroup = '1'),row=5, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['solid percentage'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='solid percentage',line=dict(width=3, ),legendgroup = '1'),row=6, col=1)  \n",
    "\n",
    "\n",
    "#for i in range(1,6):\n",
    "#   for j in range(1,4):\n",
    "#        fig.update_xaxes(tickformat=\"%H:%M\",row=i, col=j)\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=1500, title_text=\"Temporal signal analysis\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "#\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH'))\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH predict'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"HH TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='HH TPH'))\n",
    "\n",
    "fig.update_layout(height=500, width=1200, title_text=\"TPH vs TPH predict\"#,xaxis6_rangeslider_visible=True\n",
    ",#template=\"plotly_dark\"\n",
    ")                   \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 2022-02\n",
    "test_time_serie=Xtest[\"2022-02\"]\n",
    "test_time_serie[\"TPH\"]=Ytest[\"2022-02\"]\n",
    "test_time_serie[\"TPH predict\"]=pipe.predict(test_time_serie)\n",
    "\n",
    "\n",
    "# Métricas\n",
    "print('R2: ',r2_score(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"]),'\\n','RMSE: ',mean_squared_error(test_time_serie[\"TPH\"], test_time_serie[\"TPH predict\"], squared=False))\n",
    "test_time_serie[\"TPH\"]=test_time_serie[\"TPH\"].shift(10)\n",
    "test_time_serie.dropna(inplace=True)\n",
    "data=test_time_serie\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos=tuple([\"TPH & HH TPH\", \"charge cell\",\"granulometry\",\"SPI\",\"speed\",\"solid percentage\"])\n",
    "fig = make_subplots(\n",
    "    rows=6, cols=1,\n",
    "    subplot_titles=titulos,\n",
    "    #subplot_titles=tuple(\"TPH y HH TPH,\"),\n",
    "     shared_xaxes=True\n",
    "    )\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['TPH predict'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"TPH predict\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH TPH'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"HH TPH\",line=dict(width=3, ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "#fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"], ##FF6511\n",
    "#                    mode='lines',\n",
    "#                    name=\"regressor model TPH\",line=dict(width=1,color=\"black\" ),legendgroup = '1'),row=1, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['HH charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1) \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['LL charge cell'], \n",
    "                    mode='lines',\n",
    "                    name=\"charge cell\",line=dict(width=3, ),legendgroup = '1'),row=2, col=1)   \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['granulometry'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='granulometry',line=dict(width=3,),legendgroup = '1'),row=3, col=1)  \n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['sag power index'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"sag power index\",line=dict(width=3, ),legendgroup = '1'),row=4, col=1)  \n",
    "\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['speed'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name=\"speed\",line=dict(width=3, ),legendgroup = '1'),row=5, col=1)  \n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data['solid percentage'], ##FF6511\n",
    "                    mode='lines',\n",
    "                    name='solid percentage',line=dict(width=3, ),legendgroup = '1'),row=6, col=1)  \n",
    "\n",
    "\n",
    "#for i in range(1,6):\n",
    "#   for j in range(1,4):\n",
    "#        fig.update_xaxes(tickformat=\"%H:%M\",row=i, col=j)\n",
    "\n",
    "\n",
    "fig.update_layout(height=1000, width=1500, title_text=\"Temporal signal analysis\")\n",
    "fig.update_layout(hovermode=\"x unified\")\n",
    "#\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH'))\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"TPH predict\"],\n",
    "                    mode='lines',\n",
    "                    name='TPH predict'))\n",
    "\n",
    "fig.add_trace(go.Scatter(x=data.index, y=data[\"HH TPH\"],\n",
    "                    mode='lines',\n",
    "                    name='HH TPH'))\n",
    "\n",
    "fig.update_layout(height=500, width=1200, title_text=\"TPH vs TPH predict\"#,xaxis6_rangeslider_visible=True\n",
    ",#template=\"plotly_dark\"\n",
    ")                   \n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anglo_american",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Mar  3 2021, 15:03:14) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffcddc64120913561610521d74b4de27f3c5fcc7261dc5b14d51ddc2c606b013"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
